#!/usr/bin/env python3
"""
Database Schema Verification Script

Verifies that the actual database schema matches the expected SQLAlchemy models.
This script runs after Alembic migrations to ensure consistency.

Usage:
    python scripts/verify_schema.py

Exit Codes:
    0 - Schema is consistent
    1 - Schema inconsistencies detected
    2 - Connection error or other failure
"""

import sys
from pathlib import Path


# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from sqlalchemy import inspect

from db.database import engine
from db.models import Base


def verify_schema() -> int:
    """
    Verify database schema matches SQLAlchemy models.

    Returns:
        0 if schema is consistent, 1 if inconsistencies found, 2 on error
    """
    try:
        inspector = inspect(engine)
        errors = []

        # 1. Check all expected tables exist
        print("üîç Verifying database schema...")
        print("")

        expected_tables = set(Base.metadata.tables.keys())
        actual_tables = set(inspector.get_table_names(schema="public"))

        missing_tables = expected_tables - actual_tables
        if missing_tables:
            errors.append(f"‚ùå Missing tables: {', '.join(sorted(missing_tables))}")

        extra_tables = actual_tables - expected_tables - {"alembic_version"}
        if extra_tables:
            print(f"‚ö†Ô∏è  Extra tables (not in models): {', '.join(sorted(extra_tables))}")

        # 2. Verify critical columns for key tables
        critical_checks = {
            "songs": [
                ("id", "UUID"),
                ("task_id", "VARCHAR"),
                ("sketch_id", "UUID"),  # Critical: Added in migration d4641a241b98
                ("lyrics", "TEXT"),
                ("prompt", "TEXT"),
                ("status", "VARCHAR"),
            ],
            "song_sketches": [
                ("id", "UUID"),
                ("title", "VARCHAR"),
                ("lyrics", "TEXT"),
                ("prompt", "TEXT"),
                ("workflow", "VARCHAR"),
            ],
            "song_choices": [
                ("id", "UUID"),
                ("song_id", "UUID"),
                ("mp3_url", "VARCHAR"),
                ("flac_url", "VARCHAR"),
            ],
            "conversations": [
                ("id", "UUID"),
                ("title", "VARCHAR"),
                ("model", "VARCHAR"),
                ("system_context", "TEXT"),
            ],
            "lyric_parsing_rules": [
                ("id", "INTEGER"),
                ("pattern", "TEXT"),
                ("replacement", "TEXT"),
                ("rule_type", "VARCHAR"),
                ("active", "BOOLEAN"),
            ],
        }

        for table_name, expected_columns in critical_checks.items():
            if table_name not in actual_tables:
                continue  # Already reported as missing

            actual_columns = {col["name"]: col for col in inspector.get_columns(table_name, schema="public")}

            for col_name, expected_type_prefix in expected_columns:
                if col_name not in actual_columns:
                    errors.append(f"‚ùå Table '{table_name}' missing column: {col_name}")
                else:
                    actual_type = str(actual_columns[col_name]["type"]).upper()
                    if not actual_type.startswith(expected_type_prefix):
                        errors.append(
                            f"‚ùå Table '{table_name}' column '{col_name}' "
                            f"has type {actual_type}, expected {expected_type_prefix}*"
                        )

        # 3. Verify critical foreign keys
        critical_fks = {
            "songs": [("fk_songs_sketch_id", "song_sketches")],
            "song_choices": [("song_choices_song_id_fkey", "songs")],
            "messages": [("messages_conversation_id_fkey", "conversations")],
        }

        for table_name, expected_fks in critical_fks.items():
            if table_name not in actual_tables:
                continue

            actual_fks = inspector.get_foreign_keys(table_name, schema="public")
            actual_fk_names = {fk.get("name") for fk in actual_fks if fk.get("name")}

            for fk_name, _referred_table in expected_fks:
                # Check if FK exists (name might vary slightly)
                if not any(fk_name in name for name in actual_fk_names):
                    # Only warn, not error (FK names can vary)
                    print(f"‚ö†Ô∏è  Table '{table_name}' might be missing FK: {fk_name}")

        # 4. Report results
        print("")
        if errors:
            print("‚ùå Schema verification FAILED!")
            print("")
            for error in errors:
                print(f"  {error}")
            print("")
            print(f"Total errors: {len(errors)}")
            return 1
        else:
            print("‚úÖ Schema verification PASSED!")
            print(f"   Tables verified: {len(expected_tables)}")
            print(f"   Critical columns checked: {sum(len(cols) for cols in critical_checks.values())}")
            print("")
            return 0

    except Exception as e:
        print(f"‚ùå Schema verification ERROR: {e}")
        import traceback

        traceback.print_exc()
        return 2


if __name__ == "__main__":
    exit_code = verify_schema()
    sys.exit(exit_code)
